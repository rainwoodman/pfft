[2]ifpackageloaded#1#2 [2]ifpackageloaded#1#2 [3]ifpackageloaded#1#2#3

#1

PFFT Reference
==============

Files and Data Types
--------------------

You must include the PFFT header file by

::

    #include <pfft.h>

in the preamble of each source file that calls PFFT. This header
automatically includes :code:\`fftw.h\` and :code:\`fftw3-mpi.h\`.
Therefore, PFFT can use the :code:\`fftw:sub:`c`\ omplex\` data type
defined in :code:\`fftw.h\`, see . Note that
:code:\`fftw:sub:`c`\ omplex\` is defined to be the C99 native complex
whenever :code:\`<complex.h>\` is included *before* :code:\`<fftw.h>\`,
:code:\`<fftw-mpi.h>\` and :code:\`<pfft.h>\`. Otherwise it is defined
as

::

    typedef double fftw_complex[2];

For the sake of a clean namespace we define the wrapper data type
:code:\`pfft:sub:`c`\ omplex\` as

::

    typedef fftw_complex pfft_complex;

that can be used equivallently to :code:\`fftw:sub:`c`\ omplex\`.
Futhermore, we define the wrapper functions

::

    void *pfft_malloc(size_t n);
    double *pfft_alloc_real(size_t n);
    pfft_complex *pfft_alloc_complex(size_t n);
    void pfft_free(void *p);

as substitues for their corresponding FFTW equivalents, see . Note that
memory allocated by one of these functions must be freed with
:code:\`pfft:sub:`f`\ ree\` (or its equivalent
:code:\`fftw:sub:`f`\ ree\`). Because of the performance reasons given
in  we recommend to use one of the (or its equivalent ) allocation
functions for all arrays containing FFT inputs and outputs. However,
PFFT will also work (possibly slower) with any other memory allocation
method.

Different precisions are handled as in FFTW: That is functions and
datatypes become (single precision) or (long double precision) prefixed.
Quadruple precision is not yet supported. The main problem is that we do
not know about a suitable MPI datatype to represent .

MPI Initialization
------------------

Initialization and cleanup of PFFT in done in the same way as for
FFTW-MPI, see . In order to keep a clean name space, PFFT offers the
wrapper functions

::

    void pfft_init(void);
    void pfft_cleanup(void);

that can be used as substitutes for
:code:\`fftw:sub:`m`\ pi\ :sub:`i`\ nit\` and
:code:\`fftw:sub:`m`\ pi\ :sub:`c`\ leanup\`, respectively.

Using PFFT Plans
----------------

PFFT follows exactly the same workflow as FFTW-MPI. A plan created by
one of the functions given in Section [sec:create-plan] is executed with

::

    void pfft_execute(const pfft_plan plan);

and freed with

::

    void pfft_destroy_plan(const pfft_plan plan);

Note, that you can *not* apply
:code:\`fftw:sub:`m`\ pi\ :sub:`e`\ xecute\` or
:code:\`fftw:sub:`d`\ estroy\` on PFFT plans.

The new array execute functions are given by

::

    void pfft_execute_dft(const pfft_plan plan, pfft_complex *in, pfft_complex *out);
    void pfft_execute_dft_r2c(const pfft_plan plan, double *in, pfft_complex *out);
    void pfft_execute_dft_c2r(const pfft_plan plan, pfft_complex *in, double *out);
    void pfft_execute_r2r(const pfft_plan plan, double *in, double *out);

The arrays given by :code:\`in\` and :code:\`out\` must have the correct
size and the same alignement as the array that were used to create the
plan, just as it is the case for FFTW, see [fftw-new-array].

Data Distribution Functions
---------------------------

Complex-to-Complex FFT
~~~~~~~~~~~~~~~~~~~~~~

::

    ptrdiff_t pfft_local_size_dft_3d(
        const ptrdiff_t *n, MPI_Comm comm_cart, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);
    ptrdiff_t pfft_local_size_dft(
        int rnk_n, const ptrdiff_t *n,
        MPI_Comm comm_cart, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);
    ptrdiff_t pfft_local_size_many_dft(
        int rnk_n, const ptrdiff_t *n, const ptrdiff_t *ni, const ptrdiff_t *no,
        ptrdiff_t howmany, const ptrdiff_t *iblock, const ptrdiff_t *oblock,
        MPI_Comm comm_cart, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);

Compute the data distribution of a parallel, complex input/output
discrete Fourier transform (DFT) in two or more dimensions, returning
the number of *complex* numbers that must be allocated to hold the
parallel transform.

Arguments:

:code:\`rnk:sub:`n`\ \` is the rank of the transform (typically the size
of the arrays :code:\`n\`, :code:\`ni\`, :code:\`no\`) that can be any
integer :math:`\ge 2`. The :code:\`:sub:`3`\ d\` planner corresponds to
a :code:\`rnk:sub:`n`\ \` of 3.

The array :code:\`n\` of size :code:\`rnk:sub:`n`\ \` specifies the
transform dimensions. They can be any positive integer.

The array :code:\`ni\` of size :code:\`rnk:sub:`n`\ \` specifies the
input array dimensions. They can be any positive integer with
:code:\`ni[t] <= n[t]\` for all dimensions
:code:\`t=0,...,rnk:sub:`n`-1\`. For :code:\`ni[t]<n[t]\` the inputs
will be padded with zeros up to size :code:\`n[t]\` along the
:code:\`t\`-th dimension before the transform, see
Section [sec:pruned-fft].

The array :code:\`no\` of size :code:\`rnk:sub:`n`\ \` specifies the
output array dimensions. They can be any positive integer with
:code:\`no[t] <= n[t]\` for all dimensions
:code:\`t=0,...,rnk:sub:`n`-1\`. For :code:\`no[t]<n[t]\` the outputs
will be pruned to size :code:\`no[t]\` along the :code:\`t\`-th
dimension after the transform, see Section [sec:pruned-fft].

:code:\`howmany\` is the number of transforms to compute. The resulting
plan computes howmany transforms, where the input of the k-th transform
is at location in+k (in C pointer arithmetic) with stride
:code:\`howmany\`, and its output is at location out+k with stride
:code:\`howmany\`. The basic :code:\`pfft:sub:`p`\ lan\ :sub:`d`\ ft\`
interface corresponds to howmany=1.

:code:\`comm:sub:`c`\ art\` is a Cartesian communicator of dimension
:code:\`rnk:sub:`p`\ m\` that specifies the parallel data decomposition,
see Section [sec:data-decomp]. Most of the time, PFFT requires
:code:\`rnk:sub:`p`\ m < rnk\ :sub:`n`\ \`. The only exception is the
case :code:\`rnk:sub:`p`\ m == rnk\ :sub:`n` == 3\`, see
Section [sec:3don3d]. If an ordinary (i.e. non-Cartesian) communicator
is passed, PFFT internally converts it into a one-dimensional Cartesian
communicator while retaining the MPI ranks (this results in the FFTW-MPI
data decomposition).

The arrays :code:\`iblock\` and :code:\`oblock\` of size
:code:\`rnk:sub:`p`\ m+1\` specify the block sizes for the first
:code:\`rnk:sub:`p`\ m+1\` dimensions of the input and output data,
respectively. These must be the same block sizes as were passed to the
corresponding :code:\`local:sub:`s`\ ize\` function. You can pass
:code:\`PFFT:sub:`D`\ EFAULT\ :sub:`B`\ LOCKS\` to use PFFT’s default
block sizes. Furthermore, you can use
:code:\`PFFT:sub:`D`\ EFAULT\ :sub:`B`\ LOCK\` to set the default block
size in separate dimensions, e.g.,
:code:\`iblock[t]=PFFT:sub:`D`\ EFAULT\ :sub:`B`\ LOCK\`.

:code:\`pfft:sub:`f`\ lags\` is a bitwise OR (’:code:\`\|\`’) of zero or
more planner flags, as defined in Section [sec:flags].

The array :code:\`local:sub:`n`\ i\` of size :code:\`rnk:sub:`n`\ \`
returns the size of the local input array block in every dimension
(counted in units of complex numbers).

The array :code:\`local:sub:`is`\ tart\` of size :code:\`rnk:sub:`n`\ \`
returns the offset of the local input array block in every dimension
(counted in units of complex numbers).

The array :code:\`local:sub:`n`\ o\` of size :code:\`rnk:sub:`n`\ \`
returns the size of the local output array block in every dimension
(counted in units of complex numbers).

The array :code:\`local:sub:`os`\ tart\` of size :code:\`rnk:sub:`n`\ \`
returns the offset of the local output array block in every dimension
(counted in units of complex numbers).

In addition, the following :code:\`local:sub:`b`\ lock\` functions
compute the local data distribution of the process with MPI rank
:code:\`pid\`. The :code:\`local:sub:`s`\ ize\` interface can be
understood as a call of :code:\`local:sub:`b`\ lock\` where
:code:\`pid\` is given by
:code:\`MPI:sub:`C`\ omm\ :sub:`r`\ ank(comm\ :sub:`c`\ art, &pid)\`,
i.e., each MPI process computes its own data block. However,
:code:\`local:sub:`b`\ lock\` functions have a :code:\`void\` return
type, i.e., they omit the computation of the local array size that is
necessary to hold the parallel transform. This makes
:code:\`local:sub:`b`\ lock\` functions substantially faster in
exectuion.

::

    void pfft_local_block_dft_3d(
        const ptrdiff_t *n, MPI_Comm comm_cart, int pid, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);
    void pfft_local_block_dft(
        int rnk_n, const ptrdiff_t *n,
        MPI_Comm comm_cart, int pid, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);
    void pfft_local_block_many_dft(
        int rnk_n, const ptrdiff_t *ni, const ptrdiff_t *no,
        const ptrdiff_t *iblock, const ptrdiff_t *oblock,
        MPI_Comm comm_cart, int pid, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);

Real-to-Complex FFT
~~~~~~~~~~~~~~~~~~~

::

    ptrdiff_t pfft_local_size_dft_r2c_3d(
        const ptrdiff_t *n, MPI_Comm comm_cart, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);
    ptrdiff_t pfft_local_size_dft_r2c(
        int rnk_n, const ptrdiff_t *n,
        MPI_Comm comm_cart, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);
    ptrdiff_t pfft_local_size_many_dft_r2c(
        int rnk_n, const ptrdiff_t *n, const ptrdiff_t *ni, const ptrdiff_t *no,
        ptrdiff_t howmany, const ptrdiff_t *iblock, const ptrdiff_t *oblock,
        MPI_Comm comm_cart, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);

Compute the data distribution of a parallel, real-input/complex-output
discrete Fourier transform (DFT) in two or more dimensions, returning
the number of *complex* numbers that must be allocated to hold the
parallel transform.

Arguments are the same as for c2c transforms (see
Section [sec:local-size-c2c]) with the following exceptions:

The logical input array size :code:\`ni\` will differ from the physical
array size of the real inputs if the flag
:code:\`PFFT:sub:`P`\ ADDED\ :sub:`R`\ 2C\` is included in
:code:\`pfft:sub:`f`\ lags\`. This results from the padding at the end
of the last dimension that is necessary to align the real valued inputs
and complex valued outputs for inplace transforms, see . In contrast to
FFTW-MPI, PFFT does not pad the r2c inputs per default.

:code:\`local:sub:`n`\ i\` is counted in units of real numbers. It will
include padding

:code:\`local:sub:`is`\ tart\` is counted in units of real numbers.

The corresponding :code:\`local:sub:`b`\ lock\` functions compute the
local data distribution of the process with MPI rank :code:\`pid\`.

::

    void pfft_local_block_dft_r2c_3d(
        const ptrdiff_t *n, MPI_Comm comm_cart, int pid, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);
    void pfft_local_block_dft_r2c(
        int rnk_n, const ptrdiff_t *n,
        MPI_Comm comm_cart, int pid, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);
    void pfft_local_block_many_dft_r2c(
        int rnk_n, const ptrdiff_t *ni, const ptrdiff_t *no,
        const ptrdiff_t *iblock, const ptrdiff_t *oblock,
        MPI_Comm comm_cart, int pid, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);

Complex-to-Real FFT
~~~~~~~~~~~~~~~~~~~

::

    ptrdiff_t pfft_local_size_dft_c2r_3d(
        const ptrdiff_t *n, MPI_Comm comm_cart, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);
    ptrdiff_t pfft_local_size_dft_c2r(
        int rnk_n, const ptrdiff_t *n,
        MPI_Comm comm_cart, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);
    ptrdiff_t pfft_local_size_many_dft_c2r(
        int rnk_n, const ptrdiff_t *n, const ptrdiff_t *ni, const ptrdiff_t *no,
        ptrdiff_t howmany, const ptrdiff_t *iblock, const ptrdiff_t *oblock,
        MPI_Comm comm_cart, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);

Compute the data distribution of a parallel, complex-input/real-output
discrete Fourier transform (DFT) in two or more dimensions, returning
the number of *complex* numbers that must be allocated to hold the
parallel transform.

Arguments are the same as for c2c transforms (see
Section [sec:local-size-c2c]) with the following exceptions:

The logical output array size :code:\`no\` will differ from the physical
array size of the real outputs if the flag
:code:\`PFFT:sub:`P`\ ADDED\ :sub:`C`\ 2R\` is included in
:code:\`pfft:sub:`f`\ lags\`. This results from the padding at the end
of the last dimension that is necessary to align the real valued outputs
and complex valued inputs for inplace transforms, see . In contrast to
FFTW-MPI, PFFT does not pad the c2r outputs per default.

:code:\`local:sub:`n`\ o\` is counted in units of real numbers.

:code:\`local:sub:`os`\ tart\` is counted in units of real numbers.

The corresponding :code:\`local:sub:`b`\ lock\` functions compute the
local data distribution of the process with MPI rank :code:\`pid\`.

::

    void pfft_local_block_dft_c2r_3d(
        const ptrdiff_t *n, MPI_Comm comm_cart, int pid, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);
    void pfft_local_block_dft_c2r(
        int rnk_n, const ptrdiff_t *n,
        MPI_Comm comm_cart, int pid, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);
    void pfft_local_block_many_dft_c2r(
        int rnk_n, const ptrdiff_t *ni, const ptrdiff_t *no,
        const ptrdiff_t *iblock, const ptrdiff_t *oblock,
        MPI_Comm comm_cart, int pid, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);

Real-to-Real FFT
~~~~~~~~~~~~~~~~

::

    ptrdiff_t pfft_local_size_r2r_3d(
        const ptrdiff_t *n, MPI_Comm comm_cart, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);
    ptrdiff_t pfft_local_size_r2r(
        int rnk_n, const ptrdiff_t *n,
        MPI_Comm comm_cart, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);
    ptrdiff_t pfft_local_size_many_r2r(
        int rnk_n, const ptrdiff_t *n, const ptrdiff_t *ni, const ptrdiff_t *no,
        ptrdiff_t howmany, const ptrdiff_t *iblock, const ptrdiff_t *oblock,
        MPI_Comm comm_cart, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);

Compute the data distribution of a parallel, complex input/output
discrete Fourier transform (DFT) in two or more dimensions, returning
the number of *real* numbers that must be allocated to hold the parallel
transform.

Arguments are the same as for c2c transforms (see
Section [sec:local-size-c2c]) with the following exceptions:

:code:\`local:sub:`n`\ i\` is counted in units of real numbers.

:code:\`local:sub:`is`\ tart\` is counted in units of real numbers.

:code:\`local:sub:`n`\ o\` is counted in units of real numbers.

:code:\`local:sub:`os`\ tart\` is counted in units of real numbers.

The corresponding :code:\`local:sub:`b`\ lock\` functions compute the
local data distribution of the process with MPI rank :code:\`pid\`.

::

    void pfft_local_block_r2r_3d(
        const ptrdiff_t *n, MPI_Comm comm_cart, int pid, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);
    void pfft_local_block_r2r(
        int rnk_n, const ptrdiff_t *n,
        MPI_Comm comm_cart, int pid, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);
    void pfft_local_block_many_r2r(
        int rnk_n, const ptrdiff_t *ni, const ptrdiff_t *no,
        const ptrdiff_t *iblock, const ptrdiff_t *oblock,
        MPI_Comm comm_cart, int pid, unsigned pfft_flags,
        ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
        ptrdiff_t *local_no, ptrdiff_t *local_o_start);

Plan Creation
-------------

Complex-to-Complex FFT
~~~~~~~~~~~~~~~~~~~~~~

::

    pfft_plan pfft_plan_dft_3d(
        const ptrdiff_t *n, pfft_complex *in, pfft_complex *out, MPI_Comm comm_cart,
        int sign, unsigned pfft_flags);
    pfft_plan pfft_plan_dft(
        int rnk_n, const ptrdiff_t *n, pfft_complex *in, pfft_complex *out, MPI_Comm comm_cart,
        int sign, unsigned pfft_flags);
    pfft_plan pfft_plan_many_dft(
        int rnk_n, const ptrdiff_t *n, const ptrdiff_t *ni, const ptrdiff_t *no,
        ptrdiff_t howmany, const ptrdiff_t *iblock, const ptrdiff_t *oblock,
        pfft_complex *in, pfft_complex *out, MPI_Comm comm_cart,
        int sign, unsigned pfft_flags);
    pfft_plan pfft_plan_many_dft_skipped(
        int rnk_n, const ptrdiff_t *n, const ptrdiff_t *ni, const ptrdiff_t *no,
        ptrdiff_t howmany, const ptrdiff_t *iblock, const ptrdiff_t *oblock,
        const int *skip_trafos, pfft_complex *in, pfft_complex *out, MPI_Comm comm_cart,
        int sign, unsigned pfft_flags);

Plan a parallel, complex input/output discrete Fourier transform (DFT)
in two or more dimensions, returning an :code:\`pfft:sub:`p`\ lan\`. The
planner returns NULL if the plan cannot be created.

Arguments:

:code:\`rnk:sub:`n`\ \`, :code:\`n\`, :code:\`ni\`, :code:\`no\`,
:code:\`howmany\`, :code:\`iblock\`, :code:\`oblock\`,
:code:\`comm:sub:`c`\ art\` must be the same as passed to the
corresponding :code:\`pfft:sub:`l`\ ocal\ :sub:`s`\ ize\ :sub:`d`\ ft\`
function, see Section [sec:local-size-c2c].

The array :code:\`skip:sub:`t`\ rafos\` of size
:code:\`rnk:sub:`p`\ m+1\` specifies the serial transforms that will be
omitted. For :code:\`t=0,...,rnk:sub:`p`\ m\` set
:code:\`skip:sub:`t`\ rafos[t]=1\` if the :code:\`t\`-th serial
transformation should be computed, otherwise set
:code:\`skip:sub:`t`\ rafos[t]=0\`, see Section [sec:skip-trafo] for
more details.

:code:\`in\` and :code:\`out\` point to the complex valued input and
output arrays of the transform, which may be the same (yielding an
in-place transform). These arrays are overwritten during planning,
unless :code:\`PFFT:sub:`E`\ STIMATE \|
PFFT\ :sub:`N`\ O\ :sub:`T`\ UNE\` is used in the flags. (The arrays
need not be initialized, but they must be allocated.)

:code:\`sign\` is the sign of the exponent in the formula that defines
the Fourier transform. It can be -1 (= :code:\`PFFT:sub:`F`\ ORWARD\`)
or +1 (= :code:\`PFFT:sub:`B`\ ACKWARD\`).

:code:\`pfft:sub:`f`\ lags\` is a bitwise OR (’:code:\`\|\`’) of zero or
more planner flags, as defined in Section [sec:flags].

PFFT computes an unnormalized transform: computing a forward followed by
a backward transform (or vice versa) will result in the original data
multiplied by the size of the transform (the product of the dimensions
:code:\`n[t]\`).

Real-to-Complex FFT
~~~~~~~~~~~~~~~~~~~

::

    pfft_plan pfft_plan_dft_r2c_3d(
        const ptrdiff_t *n, double *in, pfft_complex *out, MPI_Comm comm_cart,
        int sign, unsigned pfft_flags);
    pfft_plan pfft_plan_dft_r2c(
        int rnk_n, const ptrdiff_t *n, double *in, pfft_complex *out, MPI_Comm comm_cart,
        int sign, unsigned pfft_flags);
    pfft_plan pfft_plan_many_dft_r2c(
        int rnk_n, const ptrdiff_t *n, const ptrdiff_t *ni, const ptrdiff_t *no,
        ptrdiff_t howmany, const ptrdiff_t *iblock, const ptrdiff_t *oblock,
        double *in, pfft_complex *out, MPI_Comm comm_cart,
        int sign, unsigned pfft_flags);
    pfft_plan pfft_plan_many_dft_r2c_skipped(
        int rnk_n, const ptrdiff_t *n, const ptrdiff_t *ni, const ptrdiff_t *no,
        ptrdiff_t howmany, const ptrdiff_t *iblock, const ptrdiff_t *oblock,
        const int *skip_trafos, double *in, pfft_complex *out, MPI_Comm comm_cart,
        int sign, unsigned pfft_flags);

Plan a parallel, real-input/complex-output discrete Fourier transform
(DFT) in two or more dimensions, returning an
:code:\`pfft:sub:`p`\ lan\`. The planner returns NULL if the plan cannot
be created.

Arguments:

:code:\`rnk:sub:`n`\ \`, :code:\`n\`, :code:\`ni\`, :code:\`no\`,
:code:\`howmany\`, :code:\`iblock\`, :code:\`oblock\`,
:code:\`comm:sub:`c`\ art\` must be the same as passed to the
corresponding
:code:\`pfft:sub:`l`\ ocal\ :sub:`s`\ ize\ :sub:`d`\ ft\ :sub:`r`\ 2c\`
function, see Section [sec:local-size-r2c].

:code:\`in\` and :code:\`out\` point to the real valued input and
complex valued output arrays of the transform, which may be the same
(yielding an in-place transform). These arrays are overwritten during
planning, unless :code:\`PFFT:sub:`E`\ STIMATE \|
PFFT\ :sub:`N`\ O\ :sub:`T`\ UNE\` is used in the flags. (The arrays
need not be initialized, but they must be allocated.)

:code:\`sign\` is the sign of the exponent in the formula that defines
the Fourier transform. It can be -1 (= :code:\`PFFT:sub:`F`\ ORWARD\`)
or +1 (= :code:\`PFFT:sub:`B`\ ACKWARD\`). Note that this parameter is
not part of the FFTW-MPI interface, where r2c transforms are defined to
be forward transforms. However, the backward transform can be easily
realized by an additional conjugation of the complex outputs as done by
PFFT.

Complex-to-Real FFT
~~~~~~~~~~~~~~~~~~~

::

    pfft_plan pfft_plan_dft_c2r_3d(
        const ptrdiff_t *n, pfft_complex *in, double *out, MPI_Comm comm_cart,
        int sign, unsigned pfft_flags);
    pfft_plan pfft_plan_dft_c2r(
        int rnk_n, const ptrdiff_t *n, pfft_complex *in, double *out, MPI_Comm comm_cart,
        int sign, unsigned pfft_flags);
    pfft_plan pfft_plan_many_dft_c2r(
        int rnk_n, const ptrdiff_t *n, const ptrdiff_t *ni, const ptrdiff_t *no,
        ptrdiff_t howmany, const ptrdiff_t *iblock, const ptrdiff_t *oblock,
        pfft_complex *in, double *out, MPI_Comm comm_cart,
        int sign, unsigned pfft_flags);
    pfft_plan pfft_plan_many_dft_c2r_skipped(
        int rnk_n, const ptrdiff_t *n, const ptrdiff_t *ni, const ptrdiff_t *no,
        ptrdiff_t howmany, const ptrdiff_t *iblock, const ptrdiff_t *oblock,
        const int *skip_trafos, pfft_complex *in, double *out, MPI_Comm comm_cart,
        int sign, unsigned pfft_flags);

Plan a parallel, complex-input/real-output discrete Fourier transform
(DFT) in two or more dimensions, returning an
:code:\`pfft:sub:`p`\ lan\`. The planner returns NULL if the plan cannot
be created.

Arguments:

:code:\`rnk:sub:`n`\ \`, :code:\`n\`, :code:\`ni\`, :code:\`no\`,
:code:\`howmany\`, :code:\`iblock\`, :code:\`oblock\`,
:code:\`comm:sub:`c`\ art\` must be the same as passed to the
corresponding
:code:\`pfft:sub:`l`\ ocal\ :sub:`s`\ ize\ :sub:`d`\ ft\ :sub:`c`\ 2r\`
function, see Section [sec:local-size-c2r].

:code:\`in\` and :code:\`out\` point to the complex valued input and
real valued output arrays of the transform, which may be the same
(yielding an in-place transform). These arrays are overwritten during
planning, unless :code:\`PFFT:sub:`E`\ STIMATE \|
PFFT\ :sub:`N`\ O\ :sub:`T`\ UNE\` is used in the flags. (The arrays
need not be initialized, but they must be allocated.)

:code:\`sign\` is the sign of the exponent in the formula that defines
the Fourier transform. It can be -1 (= :code:\`PFFT:sub:`F`\ ORWARD\`)
or +1 (= :code:\`PFFT:sub:`B`\ ACKWARD\`). Note that this parameter is
not part of the FFTW-MPI interface, where c2r transforms are defined to
be backward transforms. However, the forward transform can be easily
realized by an additional conjugation of the complex inputs as done by
PFFT.

Real-to-Real FFT
~~~~~~~~~~~~~~~~

::

    pfft_plan pfft_plan_r2r_3d(
        const ptrdiff_t *n, double *in, double *out, MPI_Comm comm_cart,
        const pfft_r2r_kind *kinds, unsigned pfft_flags);
    pfft_plan pfft_plan_r2r(
        int rnk_n, const ptrdiff_t *n, double *in, double *out, MPI_Comm comm_cart,
        const pfft_r2r_kind *kinds, unsigned pfft_flags);
    pfft_plan pfft_plan_many_r2r(
        int rnk_n, const ptrdiff_t *n, const ptrdiff_t *ni, const ptrdiff_t *no,
        ptrdiff_t howmany, const ptrdiff_t *iblock, const ptrdiff_t *oblock,
        double *in, double *out, MPI_Comm comm_cart,
        const pfft_r2r_kind *kinds, unsigned pfft_flags);
    pfft_plan pfft_plan_many_r2r_skipped(
        int rnk_n, const ptrdiff_t *n, const ptrdiff_t *ni, const ptrdiff_t *no,
        ptrdiff_t howmany, const ptrdiff_t *iblock, const ptrdiff_t *oblock,
        const int *skip_trafos, double *in, double *out, MPI_Comm comm_cart,
        const pfft_r2r_kind *kinds, unsigned pfft_flags);

Plan a parallel, real input/output (r2r) transform in two or more
dimensions, returning an :code:\`pfft:sub:`p`\ lan\`. The planner
returns NULL if the plan cannot be created.

Arguments:

:code:\`rnk:sub:`n`\ \`, :code:\`n\`, :code:\`ni\`, :code:\`no\`,
:code:\`howmany\`, :code:\`iblock\`, :code:\`oblock\`,
:code:\`comm:sub:`c`\ art\` must be the same as passed to the
corresponding :code:\`pfft:sub:`l`\ ocal\ :sub:`s`\ ize\ :sub:`r`\ 2r\`
function, see Section [sec:local-size-r2r].

:code:\`in\` and :code:\`out\` point to the real valued input and output
arrays of the transform, which may be the same (yielding an in-place
transform). These arrays are overwritten during planning, unless
:code:\`PFFT:sub:`E`\ STIMATE \| PFFT\ :sub:`N`\ O\ :sub:`T`\ UNE\` is
used in the flags. (The arrays need not be initialized, but they must be
allocated.)

The array :code:\`kinds\` of length :code:\`rnk:sub:`n`\ \` specifies
the kind of r2r transform that is computed in the corresponding
dimensions. Just like FFTW-MPI we compute the separable product formed
by taking each transform kind along the corresponding dimension, one
dimension after another.

FFT Execution Timer
-------------------

PFFT offers an easy way to perform run time measurements and print/write
the results.

Basis Run Time Measurements
~~~~~~~~~~~~~~~~~~~~~~~~~~~

PFFT-plans automatically accumulate the local run times of every call to
:code:\`pfft:sub:`e`\ xecute\`. For most applications it is sufficient
to print run time of a plan :code:\`ths\` averaged over all runs with

::

    void pfft_print_average_timer(
        const pfft_plan ths, MPI_Comm comm);

Note, that for each timer the maximum time over all processes is reduced
to rank :code:\`0\` of communicator :code:\`comm\`, i.e., a call to
:code:\`MPI:sub:`R`\ educe\` is performed and the output is only printed
on this process. The following function works in the same way but prints
more verbose output

::

    void pfft_print_average_timer_adv(
        const pfft_plan ths, MPI_Comm comm);

To write the averaged run time of plan :code:\`ths\` into a file called
:code:\`name\` use

::

    void pfft_write_average_timer(
        const pfft_plan ths, const char *name, MPI_Comm comm);
    void pfft_write_average_timer_adv(
        const pfft_plan ths, const char *name, MPI_Comm comm);

Again, the output is only written on rank :code:\`0\` of communicator
:code:\`comm\`.

Discard all the recorded run times with

::

    void pfft_reset_timer(
        pfft_plan ths);

This function is called per default at the end of every PFFT plan
creation function.

Advanced Timer Manipulation
~~~~~~~~~~~~~~~~~~~~~~~~~~~

In order to access the run times directly a new typedef
:code:\`pfft:sub:`t`\ imer\` is introduced. The following function
returns a copy of the timer corresponding to PFFT plan :code:\`ths\`

::

    pfft_timer pfft_get_timer(
        const pfft_plan ths);

Note that the memory of the returned :code:\`pfft:sub:`t`\ imer\` must
be released with

::

    void pfft_destroy_timer(
        pfft_timer ths);

as soon as the timer is not needed anymore.

In the following we introduce some routines to perform basic operations
on timers. For all functions with a :code:\`pfft:sub:`t`\ imer\` return
value you must use :code:\`pfft:sub:`d`\ estroy\ :sub:`t`\ imer\` in
order to release the allocated memory of the timer. Create a copy of a
PFFT-timer :code:\`orig\` with

::

    pfft_timer pfft_copy_timer(
        const pfft_timer orig);

Compute the average, local time over all runs of a timer :code:\`ths\`
with

::

    void pfft_average_timer(
        pfft_timer ths);

Create a new timer that contains the sum of two timers :code:\`sum1\`
and :code:\`sum2\` with

::

    pfft_timer pfft_add_timers(
        const pfft_timer sum1, const pfft_timer sum2);

Create a timer that contains the maximum times of all the timers
:code:\`ths\` from all processes belonging to communicator
:code:\`comm\` with

::

    pfft_timer pfft_reduce_max_timer(
        const pfft_timer ths, MPI_Comm comm);

Since this function calls :code:\`MPI:sub:`R`\ educe\`, only the first
process (rank 0) of :code:\`comm\` will get the desired data while all
the other processes have timers with undefined values.

Note, that you can not access the elements of a timer directly, since it
is only a pointer to a :code:\`struct\`. However, PFFT offers a routine
that creates an array and copies all the entries of the timer into it

::

    double* pfft_convert_timer2vec(
        const pfft_timer ths);

Remember to use :code:\`free\` in order to release the allocated memory
of the returned array at the moment it is not needed anymore. The
entries of the returned array are ordered as follows:

dimension of the process mesh :code:\`rnk:sub:`p`\ m\`

number of serial trafos :code:\`rnk:sub:`t`\ rafo\`

number of global remaps :code:\`rnk:sub:`r`\ emap\`

number of :code:\`pfft:sub:`e`\ xecute\` runs :code:\`iter\`

local run time of all runs

:code:\`rnk:sub:`n`\ \` local times of the serial trafos

:code:\`rnk:sub:`r`\ emap\` local times of the global remaps

2 times of the global remaps that are only necessary for
three-dimensional FFTs on three-dimensional process meshes

time for computing twiddled input (as needed for
:code:\`PFFT:sub:`S`\ HIFTED\ :sub:`O`\ UT\`)

time for computing twiddled output (as needed for
:code:\`PFFT:sub:`S`\ HIFTED\ :sub:`I`\ N\`)

The complementary function

::

    pfft_timer pfft_convert_vec2timer(
        const double *times);

creates a timer and fills it’s entries with the data from array
:code:\`times\`. Thereby, the entries of :code:\`times\` must be in the
same order as above.

Ghost Cell Communication
------------------------

In the following we describe the PFFT ghost cell communication module.
At the moment, PFFT ghost cell communication is restricted to
three-dimensional arrays.

Assume a three-dimensional array :code:\`data\` of size :code:\`n[3]\`
that is distributed in blocks such that each process has a local copy of
:code:\`data[k[0],k[1],k[2]]\` with

::

    local_start[t] <= k[t] < local_start[t] + local_n[t]

Here and in the following, we assume :code:\`t=0,1,2\`. The “classical”
ghost cell exchange communicates all the necessary data between
neighboring processes, such that each process gets a local copy of
:code:\`data[k[0],k[1],k[2]]\` with

::

    local_gc_start[t] <= k[t] < local_gc_start[t] + local_ngc[t]

where

::

    local_gc_start[t] = local_start[t] - gc_below[t];
    local_ngc[t] = local_n[t] + gc_below[t] + gc_above[t];

I.e., the local array block is increased in every dimension by
:code:\`gc:sub:`b`\ elow\` elements below and :code:\`gc:sub:`a`\ bove\`
elements above. Hereby, the :code:\`data\` is wrapped periodically
whenever :code:\`k[t]\` exceeds the array dimensions. The number of
ghost cells in every dimension can be chosen independently and can be
arbitrary large, i.e., PFFT ghost cell communication also handles the
case where the requested data exceeds next neighbor communication. The
number of ghost cells can even be bigger than the array size, which
results in multiple local copies of the same data elements at every
process. However, the arrays :code:\`gc:sub:`b`\ elow\` and
:code:\`gc:sub:`a`\ bove\` must be equal among all MPI processes.

PFFT ghost cell communication can work on both, the input and output
array distributions. Substitute :code:\`local:sub:`n`\ \` and
:code:\`local:sub:`s`\ tart\` by :code:\`local:sub:`n`\ i\` and
:code:\`local:sub:`is`\ tart\` if you are interested in ghost cell
communication of the input array. For ghost cell communication of the
output array, substitute :code:\`local:sub:`n`\ \` and
:code:\`local:sub:`s`\ tart\` by :code:\`local:sub:`n`\ o\` and
:code:\`local:sub:`os`\ tart\`.

Using Ghost Cell Plans
~~~~~~~~~~~~~~~~~~~~~~

We introduce a new datatype :code:\`pfft:sub:`g`\ cplan\` that stores
all the necessary information for ghost cell communication. Using a
ghost cell plan follows the typical workflow: At first, determine the
parallel data distribution; cf. Section [sec:gc:local-size]. Next,
create a ghost cell plan; cf. Section [sec:gc:plan-cdata] and
Section [sec:gc:plan-rdata]. Execute the ghost cell communication with
one of the following two collective functions

::

    void pfft_exchange(
        pfft_gcplan ths);
    void pfft_reduce(
        pfft_gcplan ths);

Hereby, a ghost cell exchange creates duplicates of local data elements
on next neighboring processes, while a ghost cell reduce is the adjoint
counter part of the exchange, i.e., it adds the sum of all the
duplicates of a local data element to the original data element.
Finally, free the allocated memory with

::

    void pfft_destroy_gcplan(
        pfft_gcplan ths);

if the plan is not needed anymore. Passing a freed plan to
:code:\`pfft:sub:`e`\ xchange\` or :code:\`pfft:sub:`r`\ educe\` results
in undefined behavior.

Data Distribution
~~~~~~~~~~~~~~~~~

Corresponding to the three interface layers for FFT planning, there are
the following three layers for computing the ghost cell data
distribution:

::

    ptrdiff_t pfft_local_size_gc_3d(
        const ptrdiff_t *local_n, const ptrdiff_t *local_start,
        const ptrdiff_t *gc_below, const ptrdiff_t *gc_above,
        ptrdiff_t *local_ngc, ptrdiff_t *local_gc_start);
    ptrdiff_t pfft_local_size_gc(
        int rnk_n, 
        const ptrdiff_t *local_n, const ptrdiff_t *local_start,
        const ptrdiff_t *gc_below, const ptrdiff_t *gc_above,
        ptrdiff_t *local_ngc, ptrdiff_t *local_gc_start);
    ptrdiff_t pfft_local_size_many_gc(
        int rnk_n,
        const ptrdiff_t *local_n, const ptrdiff_t *local_start,
        ptrdiff_t howmany,
        const ptrdiff_t *gc_below, const ptrdiff_t *gc_above,
        ptrdiff_t *local_ngc, ptrdiff_t *local_gc_start);

Hereby, :code:\`rnk:sub:`n`\ \` and :code:\`howmany\` must be the
exactly same variables that were used for the PFFT plan creation.
However, only the case :code:\`rnk:sub:`n`\ ==3\` is completely
implemented at the moment. The local array size
:code:\`local:sub:`n`\ \` must be equal to :code:\`local:sub:`n`\ i\` or
:code:\`local:sub:`n`\ o\` (computed by an appropriate call of
:code:\`pfft:sub:`l`\ ocal\ :sub:`s`\ ize\`; cf.
Section [sec:local-size]) depending on whether the ghost cell plan works
on the FFT input or output array. Analogously,
:code:\`local:sub:`s`\ tart\` becomes :code:\`local:sub:`is`\ tart\` or
:code:\`local:sub:`os`\ tart\`. The number of ghost cells is given by
the two arrays :code:\`gc:sub:`b`\ elow\` and :code:\`gc:sub:`a`\ bove\`
that must be equal among all MPI processes. All the ghost cell data
distribution functions return the local array plus ghost cell size
:code:\`local:sub:`n`\ gc\` and the corresponding offset
:code:\`local:sub:`g`\ c\ :sub:`s`\ tart\` as two arrays of length
:code:\`rnk:sub:`n`\ \`. In addition, the :code:\`ptrdiff:sub:`t`\ \`
return value gives the number of data elements that are necessary in
order to store the array plus ghost cells.

Note, that the array distribution functions do not distinguish between
real and complex valued data. That is because :code:\`local:sub:`n`\ \`
and :code:\`local:sub:`s`\ tart\` count array elements in units of
complex or real depending on the transform. In addition, it does not
matter if the local array is transposed or not, i.e., it is not
necessary to pass the flags
:code:\`PFFT:sub:`T`\ RANSPOSED\ :sub:`I`\ N\` and
:code:\`PFFT:sub:`T`\ RANSPOSED\ :sub:`O`\ UT\` to the ghost cell
distribution function. In constrast, the ghost cell plan creation
depends on the transform type as well as the transposition flags.

Memory Allocation
~~~~~~~~~~~~~~~~~

In most applications we must ensure that the data array is large enough
to suit the memory requirements of a parallel FFT and the ghost cell
communication. The following two code snippets illustrate the correct
allocation of memory in for complex valued and real valued arrays.

::

    /* Get parameters of data distribution */
    /* alloc_local, local_no, local_o_start are given in complex units */
    /* local_ni, local_i_start are given in real units */
    alloc_local = pfft_local_size_dft_r2c_3d(n, comm_cart_2d, PFFT_TRANSPOSED_NONE,
        local_ni, local_i_start, local_no, local_o_start);

    /* alloc_local_gc, local_ngc, local_gc_start are given in complex units */
    alloc_local_gc = pfft_local_size_gc_3d(
        local_no, local_o_start, gc_below, gc_above,
        local_ngc, local_gc_start);

    /* Allocate enough memory for FFT and ghost cells */
    pfft_complex *cdata = pfft_alloc_complex(alloc_local_gc > alloc_local ? alloc_local_gc : alloc_local);

Here, :code:\`alloc:sub:`l`\ ocal\` gives the number of data elements
that are necessary to hold all steps of the parallel FFT, while
:code:\`alloc:sub:`l`\ ocal\ :sub:`g`\ c\` gives the number of data
elements that are necessary to hold all steps of the ghost cell
communication. Note that we took the maximum of these both numbers as
argument for :code:\`pfft:sub:`a`\ lloc\ :sub:`c`\ omplex\`. The code
snippet for real valued arrays looks very similar.

::

    /* Get parameters of data distribution */
    /* alloc_local, local_no, local_o_start are given in complex units */
    /* local_ni, local_i_start are given in real units */
    alloc_local = pfft_local_size_dft_r2c_3d(n, comm_cart_2d, PFFT_TRANSPOSED_NONE,
        local_ni, local_i_start, local_no, local_o_start);

    /* alloc_local_gc, local_ngc, local_gc_start are given in real units */
    alloc_local_gc = pfft_local_size_gc_3d(
        local_ni, local_i_start, gc_below, gc_above,
        local_ngc, local_gc_start);

    /* Allocate enough memory for FFT and ghost cells */
    double *rdata = pfft_alloc_real(alloc_local_gc > 2*alloc_local ? alloc_local_gc : 2*alloc_local);

Note that the number of real valued data elements is given by two times
:code:\`alloc:sub:`l`\ ocal\` for r2c transforms, whereas the last line
would change into

::

    double *rdata = pfft_alloc_real(alloc_local_gc > alloc_local ? alloc_local_gc : alloc_local);

for r2r transforms.

Plan Creation for Complex Data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The following functions create ghost cell plans that operate on complex
valued arrays, i.e.,

c2c inputs,

c2c outputs,

r2c outputs (use flag :code:\`PFFT:sub:`G`\ C\ :sub:`C`\ 2R\`), and

c2r inputs (use flag :code:\`PFFT:sub:`G`\ C\ :sub:`R`\ 2C\`).

Corresponding to the three interface layers for FFT planning, there are
the following three layers for creating a complex valued ghost cell
plan:

::

    pfft_gcplan pfft_plan_cgc_3d(
        const ptrdiff_t *n,
        const ptrdiff_t *gc_below, const ptrdiff_t *gc_above,
        pfft_complex *data, MPI_Comm comm_cart, unsigned gc_flags);
    pfft_gcplan pfft_plan_cgc(
        int rnk_n, const ptrdiff_t *n,
        const ptrdiff_t *gc_below, const ptrdiff_t *gc_above,
        pfft_complex *data, MPI_Comm comm_cart, unsigned gc_flags);
    pfft_gcplan pfft_plan_many_cgc(
        int rnk_n, const ptrdiff_t *n,
        ptrdiff_t howmany, const ptrdiff_t *block,
        const ptrdiff_t *gc_below, const ptrdiff_t *gc_above,
        pfft_complex *data, MPI_Comm comm_cart, unsigned gc_flags);

Hereby, :code:\`rnk:sub:`n`\ \`, :code:\`n\`, :code:\`howmany\` and
:code:\`comm:sub:`c`\ art\` must be the variables that were used for the
PFFT plan creation. However, only the case :code:\`rnk:sub:`n`\ ==3\` is
completely implemented at the moment. Remember that :code:\`n\` is the
logical FFT size just as it is the case for FFT planning. The block size
:code:\`block\` must be equal to :code:\`iblock\` or :code:\`oblock\`
depending on whether the ghost cell plan works on the FFT input or
output array. Analogously, :code:\`data\` becomes :code:\`in\` or
:code:\`out\`. Set the number of ghost cells by
:code:\`gc:sub:`b`\ elow\` and :code:\`gc:sub:`a`\ bove\` as described
in Section [sec:gc]. The flags :code:\`gc:sub:`f`\ lags\` must be set
appropriately to the flags that were passed to the FFT planner.
Table [tab:map-cgcflags] shows the ghost cell planner flags that must be
set in dependence on the listed FFT planner flags.

[h]

+----------------------------------------------------+-----------------------------------------------------------------+
| FFT flag                                           | ghost cell flag                                                 |
+====================================================+=================================================================+
| :code:\`PFFT:sub:`T`\ RANSPOSED\ :sub:`N`\ ONE\`   | :code:\`PFFT:sub:`G`\ C\ :sub:`T`\ RANSPOSED\ :sub:`N`\ ONE\`   |
+----------------------------------------------------+-----------------------------------------------------------------+
| :code:\`PFFT:sub:`T`\ RANSPOSED\ :sub:`I`\ N\`     | :code:\`PFFT:sub:`G`\ C\ :sub:`T`\ RANSPOSED\`                  |
+----------------------------------------------------+-----------------------------------------------------------------+
| :code:\`PFFT:sub:`T`\ RANSPOSED\ :sub:`O`\ UT\`    | :code:\`PFFT:sub:`G`\ C\ :sub:`T`\ RANSPOSED\`                  |
+----------------------------------------------------+-----------------------------------------------------------------+

[tab:map-cgcflags]

In addition, we introduce the flag
:code:\`PFFT:sub:`G`\ C\ :sub:`R`\ 2C\` (and its equivalent
:code:\`PFFT:sub:`G`\ C\ :sub:`C`\ 2R\`) to handle the complex array
storage format of r2c and c2r transforms. In fact, these two flags imply
an ordinary complex valued ghost cell communication on an array of size
:code:\`n[0] x ... x n[rnk\ :sub:`n`-2] x (n[rnk:sub:`n`-1]/2+1)\`.
Please note that we wrongly assume periodic boundary conditions in this
case. Therefore, you should ignore the data elements with the last index
behind :code:\`n[rnk:sub:`n`-1]/2\`.

Plan Creation for Real Data
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The following functions create ghost cell plans that operate on real
valued arrays, i.e.,

r2r inputs,

r2r outputs,

r2c inputs, and

c2r outputs.

Corresponding to the three interface layers for FFT planning, there are
the following three layers for creating a real valued ghost cell plan:

::

    pfft_gcplan pfft_plan_rgc_3d(
        const ptrdiff_t *n,
        const ptrdiff_t *gc_below, const ptrdiff_t *gc_above,
        double *data, MPI_Comm comm_cart, unsigned gc_flags);
    pfft_gcplan pfft_plan_rgc(
        int rnk_n, const ptrdiff_t *n,
        const ptrdiff_t *gc_below, const ptrdiff_t *gc_above,
        double *data, MPI_Comm comm_cart, unsigned gc_flags);
    pfft_gcplan pfft_plan_many_rgc(
        int rnk_n, const ptrdiff_t *n,
        ptrdiff_t howmany, const ptrdiff_t *block,
        const ptrdiff_t *gc_below, const ptrdiff_t *gc_above,
        double *data, MPI_Comm comm_cart, unsigned gc_flags);

Hereby, :code:\`rnk:sub:`n`\ \`, :code:\`n\`, :code:\`howmany\` and
:code:\`comm:sub:`c`\ art\` must be the variables that were used for the
PFFT plan creation. Remember that :code:\`n\` is the logical FFT size
just as it is the case for FFT planning. The block size :code:\`block\`
must be equal to :code:\`iblock\` or :code:\`oblock\` depending on
whether the ghost cell plan works on the FFT input or output array.
Analogously, :code:\`data\` becomes :code:\`in\` or :code:\`out\`. Set
the number of ghost cells by :code:\`gc:sub:`b`\ elow\` and
:code:\`gc:sub:`a`\ bove\` as described in Section [sec:gc:local-size].
The flags :code:\`gc:sub:`f`\ lags\` must be set appropriately to the
flags that were passed to the FFT planner. Table [tab:map-rgcflags]
shows the ghost cell planner flags that must be set in dependence on the
listed FFT planner flags.

[h]

+----------------------------------------------------+-----------------------------------------------------------------+
| FFT flag                                           | ghost cell flag                                                 |
+====================================================+=================================================================+
| :code:\`PFFT:sub:`T`\ RANSPOSED\ :sub:`N`\ ONE\`   | :code:\`PFFT:sub:`G`\ C\ :sub:`T`\ RANSPOSED\ :sub:`N`\ ONE\`   |
+----------------------------------------------------+-----------------------------------------------------------------+
| :code:\`PFFT:sub:`T`\ RANSPOSED\ :sub:`I`\ N\`     | :code:\`PFFT:sub:`G`\ C\ :sub:`T`\ RANSPOSED\`                  |
+----------------------------------------------------+-----------------------------------------------------------------+
| :code:\`PFFT:sub:`T`\ RANSPOSED\ :sub:`O`\ UT\`    | :code:\`PFFT:sub:`G`\ C\ :sub:`T`\ RANSPOSED\`                  |
+----------------------------------------------------+-----------------------------------------------------------------+
| :code:\`PFFT:sub:`P`\ ADDED\ :sub:`R`\ 2C\`        | :code:\`PFFT:sub:`G`\ C\ :sub:`P`\ ADDED\ :sub:`R`\ 2C\`        |
+----------------------------------------------------+-----------------------------------------------------------------+
| :code:\`PFFT:sub:`P`\ ADDED\ :sub:`C`\ 2R\`        | :code:\`PFFT:sub:`G`\ C\ :sub:`P`\ ADDED\ :sub:`C`\ 2R\`        |
+----------------------------------------------------+-----------------------------------------------------------------+

[tab:map-rgcflags]

Note that the flag
:code:\`PFFT:sub:`G`\ C\ :sub:`P`\ ADDED\ :sub:`R`\ 2C\` (or its
equivalent :code:\`PFFT:sub:`G`\ C\ :sub:`P`\ ADDED\ :sub:`C`\ 2R\`)
implies an ordinary real valued ghost cell communication on an array of
size :code:\`n[0] x ... x n[rnk\ :sub:`n`-2] x
2\*(n[rnk\ :sub:`n`-1]/2+1)\`. Especially, the padding elements will be
handles as normal data points, i.e., you must we aware that the numbers
of ghost cells :code:\`gc:sub:`b`\ elow[rnk\ :sub:`n`-1]\` and
:code:\`gc:sub:`a`\ bove[rnk\ :sub:`n`-1]\` include the number of
padding elements.

Inofficial Flags
~~~~~~~~~~~~~~~~

Ghost Cell Execution Timer
~~~~~~~~~~~~~~~~~~~~~~~~~~

PFFT ghost cell plans automatically accumulate the local run times of
every call to :code:\`pfft:sub:`e`\ xchange\` and
:code:\`pfft:sub:`r`\ educe\`. For most applications it is sufficient to
print run time of a plan :code:\`ths\` averaged over all runs with

::

    void pfft_print_average_gctimer(
        const pfft_gcplan ths, MPI_Comm comm);

Note, that for each timer the maximum time over all processes is reduced
to rank :code:\`0\` of communicator :code:\`comm\`, i.e., a call to
:code:\`MPI:sub:`R`\ educe\` is performed and the output is only printed
on this process. The following function works in the same way but prints
more verbose output

::

    void pfft_print_average_gctimer_adv(
        const pfft_gcplan ths, MPI_Comm comm);

To write the averaged run time of a ghost cell plan :code:\`ths\` into a
file called :code:\`name\` use

::

    void pfft_write_average_gctimer(
        const pfft_gcplan ths, const char *name, MPI_Comm comm);
    void pfft_write_average_gctimer_adv(
        const pfft_gcplan ths, const char *name, MPI_Comm comm);

Again, the output is only written on rank :code:\`0\` of communicator
:code:\`comm\`.

Discard all the recorded run times with

::

    void pfft_reset_gctimers(
        pfft_gcplan ths);

This function is called per default at the end of every ghost cell plan
creation function.

In order to access the run times directly a new typedef
:code:\`pfft:sub:`t`\ imer\` is introduced. The following functions
return a copy of the timer corresponding to ghost cell plan
:code:\`ths\` that accumulated the time for ghost cell exchange or ghost
cell reduce, respectively:

::

    pfft_gctimer pfft_get_gctimer_exg(
        const pfft_gcplan ths);
    pfft_gctimer pfft_get_gctimer_red(
        const pfft_gcplan ths);

Note that the memory of the returned :code:\`pfft:sub:`g`\ ctimer\` must
be released with

::

    void pfft_destroy_gctimer(
        pfft_gctimer ths);

as soon as the timer is not needed anymore.

In the following we introduce some routines to perform basic operations
on timers. For all functions with a :code:\`pfft:sub:`g`\ ctimer\`
return value you must use
:code:\`pfft:sub:`d`\ estroy\ :sub:`g`\ ctimer\` in order to release the
allocated memory of the timer. Create a copy of a ghost cell timer
:code:\`orig\` with

::

    pfft_gctimer pfft_copy_gctimer(
        const pfft_gctimer orig);

Compute the average, local time over all runs of a timer :code:\`ths\`
with

::

    void pfft_average_gctimer(
        pfft_gctimer ths);

Create a new timer that contains the sum of two timers :code:\`sum1\`
and :code:\`sum2\` with

::

    pfft_gctimer pfft_add_gctimers(
        const pfft_gctimer sum1, const pfft_gctimer sum2);

Create a timer that contains the maximum times of all the timers
:code:\`ths\` from all processes belonging to communicator
:code:\`comm\` with

::

    pfft_gctimer pfft_reduce_max_gctimer(
        const pfft_gctimer ths, MPI_Comm comm);

Since this function calls :code:\`MPI:sub:`R`\ educe\`, only the first
process (rank 0) of :code:\`comm\` will get the desired data while all
the other processes have timers with undefined values.

Note, that you can not access the elements of a timer directly, since it
is only a pointer to a :code:\`struct\`. However, PFFT offers a routine
that creates an array and copies all the entries of the timer into it

::

    void pfft_convert_gctimer2vec(
        const pfft_gctimer ths, double *times);

Remember to use :code:\`free\` in order to release the allocated memory
of the returned array at the moment it is not needed anymore. The
entries of the returned array are ordered as follows:

number of :code:\`pfft:sub:`e`\ xecute\` runs :code:\`iter\`

local run time of all runs

local run time of zero padding (make room for incoming ghost cells and
init with zeros)

local run time of the ghost cell exchange or reduce (depending on the
timer)

The complementary function

::

    pfft_gctimer pfft_convert_vec2gctimer(
        const double *times);

creates a timer and fills it’s entries with the data from array
:code:\`times\`. Thereby, the entries of :code:\`times\` must be in the
same order as above.

Useful Tools
------------

The following functions are useful tools but are not necessarily needed
to perform parallel FFTs.

Initializing Complex Inputs and Checking Outputs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To fill a complex array :code:\`data\` with reproducible, complex values
you can use one of the functions

::

    void pfft_init_input_complex_3d(
        const ptrdiff_t *n,
        const ptrdiff_t *local_n, const ptrdiff_t *local_n_start,
        pfft_complex *data);
    void pfft_init_input_complex(
        int rnk_n, const ptrdiff_t *n,
        const ptrdiff_t *local_n, const ptrdiff_t *local_start,
        pfft_complex *data);

Hereby, the arrays :code:\`n\`, :code:\`local:sub:`n`\ \` and
:code:\`local:sub:`ns`\ tart\` of length :code:\`rnk:sub:`n`\ \`
(:code:\`rnk:sub:`n`\ ==3\` for :code:\`:sub:`3`\ d\`) give the size of
the FFT, the local array size and the local array offset as computed by
the array distribution functions described in Section [sec:local-size]
The functions

::

    double pfft_check_output_complex_3d(
        const ptrdiff_t *n, 
        const ptrdiff_t *local_n, const ptrdiff_t *local_n_start,
        const pfft_complex *data, MPI_Comm comm);
    double pfft_check_output_complex(
        int rnk_n, const ptrdiff_t *n,
        const ptrdiff_t *local_n, const ptrdiff_t *local_start,
        const pfft_complex *data, MPI_Comm comm);

compute the :math:`l_1`-norm between the elements of array
:code:\`data\` and values produced by
:code:\`pfft:sub:`i`\ nit\ :sub:`i`\ nput\ :sub:`c`\ omplex\ :sub:`3`\ d\`,
:code:\`pfft:sub:`i`\ nit\ :sub:`i`\ nput\ :sub:`c`\ omplex\`. In
addition, we supply the following functions for setting all the input
data to zero at once

::

    void pfft_clear_input_complex_3d(
        const ptrdiff_t *n,
        const ptrdiff_t *local_n, const ptrdiff_t *local_n_start,
        pfft_complex *data);
    void pfft_clear_input_complex(
        int rnk_n, const ptrdiff_t *n,
        const ptrdiff_t *local_n, const ptrdiff_t *local_start,
        pfft_complex *data);

Note, that these functions can be combined for a quick consistency check
of the FFT. Since a forward FFT followed by a backward FFT reproduces
the inputs up to a scaling factor, the following code snippet should
give a result equal to zero up to machine precision.

::

    /* Initialize input with random numbers */
    pfft_init_input_complex_3d(n, local_ni, local_i_start,
        in);

    /* execute parallel forward FFT */
    pfft_execute(plan_forw);

    /* clear the old input */
    if(in != out) 
      pfft_clear_input_complex_3d(n, local_ni, local_i_start, in);

    /* execute parallel backward FFT */
    pfft_execute(plan_back);

    /* Scale data */
    for(ptrdiff_t l=0; l < local_ni[0] * local_ni[1] * local_ni[2]; l++)
      in[l] /= (n[0]*n[1]*n[2]);

    /* Print error of back transformed data */
    err = pfft_check_output_complex_3d(n, local_ni, local_i_start, in, comm_cart_2d);
    pfft_printf(comm_cart_2d, "Error after one forward and backward trafo of size n=(%td, %td, %td):\n", n[0], n[1], n[2]);
    pfft_printf(comm_cart_2d, "maxerror = %6.2e;\n", err);

Hereby, we set all inputs equal to zero after the forward FFT in order
to be sure that all the final results are actually computed by the
backward FFT instead of being a buggy relict of the forward transform.

Initializing Real Inputs and Checking Outputs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To fill a real array :code:\`data\` with reproducible, real values use
one of the functions

::

    void pfft_init_input_real_3d(
        const ptrdiff_t *n,
        const ptrdiff_t *local_n, const ptrdiff_t *local_n_start,
        double *data);
    void pfft_init_input_real(
        int rnk_n, const ptrdiff_t *n,
        const ptrdiff_t *local_n, const ptrdiff_t *local_start,
        double *data);

Hereby, the arrays :code:\`n\`, :code:\`local:sub:`n`\ \` and
:code:\`local:sub:`ns`\ tart\` give the size of the FFT, the local array
size and the local array offset as computed by the array distribution
functions described in Section [sec:local-size] The functions

::

    double pfft_check_output_real_3d(
        const ptrdiff_t *n,
        const ptrdiff_t *local_n, const ptrdiff_t *local_n_start,
        const pfft_complex *data, MPI_Comm comm);
    double pfft_check_output_real(
        int rnk_n, const ptrdiff_t *n,
        const ptrdiff_t *local_n, const ptrdiff_t *local_start,
        const pfft_complex *data, MPI_Comm comm);

compute the :math:`l_1`-norm between the elements of array
:code:\`data\` and values produced by
:code:\`pfft:sub:`i`\ nit\ :sub:`i`\ nput\ :sub:`r`\ eal\ :sub:`3`\ d\`,
:code:\`pfft:sub:`i`\ nit\ :sub:`i`\ nput\ :sub:`r`\ eal\`. In addition,
we supply the following functions for setting all the input data to zero
at once

::

    void pfft_clear_input_real_3d(
        const ptrdiff_t *n,
        const ptrdiff_t *local_n, const ptrdiff_t *local_n_start,
        double *data);
    void pfft_clear_input_real(
        int rnk_n, const ptrdiff_t *n,
        const ptrdiff_t *local_n, const ptrdiff_t *local_start,
        double *data);

Note, that both
:code:\`pfft:sub:`i`\ nit\ :sub:`i`\ nput\ :sub:`r`\ eal\*\` functions
will set all array elements to zero were :code:\`local:sub:`n` +
local\ :sub:`ns`\ tart >= n\`. In addition, both
:code:\`pfft:sub:`c`\ heck\ :sub:`o`\ utput\ :sub:`r`\ eal\*\` function
will ignore all the errors resulting from these elements. Therefore, it
is safe to use all these functions for a consistency check of a r2c
transform followed by a c2r transform since all padding elements will be
ignored.

Initializing r2c/c2r Inputs and Checking Outputs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The real inputs of a r2c transform can be initialized with the functions
decribed in Section [sec:init-data-3d-r2r]. However, generating suitable
inputs for a c2r transform requires more caution. In order to get real
valued results of a DFT the complex input coefficients need to satisfy
an radial Hermitian symmetry, i.e.,
:math:`X[{\ensuremath{\boldsymbol{k}}}] = {X^*[-{\ensuremath{\boldsymbol{k}}}]}`.
We use the following trick to generate the complex input values for c2r
transforms. Assume any :math:`{\ensuremath{\boldsymbol{N}}}`-periodic
complex valued function :math:`f`. It can be easily shown that the
values
:math:`X[{\ensuremath{\boldsymbol{k}}}] := \frac{1}{2}\left(f({\ensuremath{\boldsymbol{k}}})+f^*(-{\ensuremath{\boldsymbol{k}}})\right)`
satisfy the radial Hermitian symmetry.

To fill a complex array :code:\`data\` with reproducible, complex values
that fulfill the radial Hermitian symmetry use one of the functions

::

    void pfft_init_input_complex_hermitian_3d(
        const ptrdiff_t *n,
        const ptrdiff_t *local_n, const ptrdiff_t *local_n_start,
        double *data);
    void pfft_init_input_complex_hermitian(
        int rnk_n, const ptrdiff_t *n,
        const ptrdiff_t *local_n, const ptrdiff_t *local_start,
        double *data);

Hereby, the arrays :code:\`n\`, :code:\`local:sub:`n`\ \` and
:code:\`local:sub:`ns`\ tart\` give the size of the FFT, the local array
size and the local array offset as computed by the array distribution
functions described in Section [sec:local-size] The functions

::

    double pfft_check_output_complex_hermitian_3d(
        const ptrdiff_t *n,
        const ptrdiff_t *local_n, const ptrdiff_t *local_n_start,
        const pfft_complex *data, MPI_Comm comm);
    double pfft_check_output_complex_hermitian(
        int rnk_n, const ptrdiff_t *n,
        const ptrdiff_t *local_n, const ptrdiff_t *local_start,
        const pfft_complex *data, MPI_Comm comm);

compute the :math:`l_1`-norm between the elements of array
:code:\`data\` and values produced by
:code:\`pfft:sub:`i`\ nit\ :sub:`i`\ nput\ :sub:`c`\ omplex\ :sub:`h`\ ermitian\ :sub:`3`\ d\`,
:code:\`pfft:sub:`i`\ nit\ :sub:`i`\ nput\ :sub:`c`\ omplex\ :sub:`h`\ ermitian\`.
In addition, we supply the following functions for setting all the input
data to zero at once

::

    void pfft_clear_input_complex_hermitian_3d(
        const ptrdiff_t *n,
        const ptrdiff_t *local_n, const ptrdiff_t *local_n_start,
        pfft_complex *data);
    void pfft_clear_input_complex_hermitian(
        int rnk_n, const ptrdiff_t *n,
        const ptrdiff_t *local_n, const ptrdiff_t *local_start,
        pfft_complex *data);

Note, that these functions can also be used in order to generate complex
inputs with radial Hermitian symmetry for ordinary c2c transforms. Of
course the results of such a c2c DFT will have all imaginary parts equal
to zero up to machine precision.

Operations on Arrays of Type :code:\`ptrdiff:sub:`t`\ \`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The following routines are shortcuts for the elementwise manipulation of
:code:\`ptrdiff:sub:`t`\ \` valued arrays. In the following, all arrays
:code:\`vec\`, :code:\`vec1\`, and :code:\`vec2\` are of length
:code:\`d\` and type :code:\`ptrdiff:sub:`t`\ \`.

::

    ptrdiff_t pfft_prod_INT(
        int d, const ptrdiff_t *vec);

Returns the product over all elements of :code:\`vec\`.

::

    ptrdiff_t pfft_sum_INT(
        int d, const ptrdiff_t *vec);

Returns the sum over all elements of :code:\`vec\`.

::

    int pfft_equal_INT(
        int d, const ptrdiff_t *vec1, const ptrdiff_t *vec2);

Returns 1 if both arrays have equal entries, 0 otherwise.

::

    void pfft_vcopy_INT(
        int d, const ptrdiff_t *vec1,
        ptrdiff_t *vec2);

Copies the elements of :code:\`vec1\` into :code:\`vec2\`.

::

    void pfft_vadd_INT(
        int d, const ptrdiff_t *vec1, const ptrdiff_t *vec2,
        ptrdiff_t *sum);

Fills :code:\`sum\` with the componentwise sum of :code:\`vec1\` and
:code:\`vec2\`.

::

    void pfft_vsub_INT(
        int d, const ptrdiff_t *vec1, const ptrdiff_t *vec2,
        ptrdiff_t *sum);

Fills :code:\`sum\` with the componentwise difference of :code:\`vec1\`
and :code:\`vec2\`.

Print Three-Dimensional Arrays in Parallel
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Use the following routine to print the elements of a block decomposed
three-dimensional (real or complex valued) array :code:\`data\` in a
nicely formatted way.

::

    void pfft_apr_real_3d(
        const double *data,
        const ptrdiff_t *local_n, const ptrdiff_t *local_start,
        const char *name, MPI_Comm comm);
    void pfft_apr_complex_3d(
        const pfft_complex *data,
        const ptrdiff_t *local_n, const ptrdiff_t *local_start,
        const char *name, MPI_Comm comm);

Obviously, this makes only sense for arrays of moderate size. The block
decomposition is given by :code:\`local:sub:`n`\ \`,
:code:\`local:sub:`ns`\ tart\` as returned by the array distribution
function decribed in Section [sec:local-size]. Furthermore, some
arbitrary string :code:\`name\` can be added at the beginning of each
output - typically this will be the name of the array. Communicator
:code:\`comm\` must be suitable to the block decomposition and is used
to synchronize the outputs over all processes.

Generalizations for the case where the dimensions of the local arrays
are permuted are given by

::

    void pfft_apr_real_permuted_3d(
        const double *data,
        const ptrdiff_t *local_n, const ptrdiff_t *local_start,
        int perm0, int perm1, int perm2,
        const char *name, MPI_Comm comm);
    void pfft_apr_complex_permuted_3d(
        const pfft_complex *data,
        const ptrdiff_t *local_n, const ptrdiff_t *local_start,
        int perm0, int perm1, int perm2,
        const char *name, MPI_Comm comm);

Hereby, :code:\`perm0\`, :code:\`perm1\`, and :code:\`perm2\` give the
array’s permutation of dimension.

Reading Command Line Arguments
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The following function offers a simple way to read command line
arguments into an array :code:\`parameter\`.

::

    void pfft_get_args(
        int argc, char **argv, const char *name,
        int neededArgs, unsigned type,
        void *parameter);

Hereby, :code:\`argc\` and :code:\`argv\` are the standard argument of
the :code:\`main\` routine. Furthermore, :code:\`name\`,
:code:\`neededAgrs\`, and :code:\`type\` give the name, number of
entries and the type of the command line argument. Supported types are
:code:\`PFFT:sub:`I`\ NT\`, :code:\`PFFT:sub:`P`\ TRDIFF\ :sub:`T`\ \`,
:code:\`PFFT:sub:`F`\ LOAT\`, :code:\`PFFT:sub:`D`\ OUBLE\`, and
:code:\`PFFT:sub:`U`\ NSIGNED\`, which denote the standard C type that
is used for typecasting. In addition, you can use the special type
:code:\`PFFT:sub:`S`\ WITCH\` that is an integer type equal to one if
the corresponding command line argument is given. The array
:code:\`parameter\` must be of sufficient size to hold
:code:\`neededArgs\` elements of the given data type. Special attention
is given

For example, a program containing the following code snippet

::

    double x=0.1;
    pfft_get_args(argc, argv, "-pfft_x", 1, PFFT_DOUBLE, &x);
    int np[2]={2,1};
    pfft_get_args(argc, argv, "-pfft_np", 2, PFFT_INT, np);
    ptrdiff_t n[3]={32,32,32};
    pfft_get_args(argc, argv, "-pfft_n", 3, PFFT_PTRDIFF_T, n);
    int switch=0;
    pfft_get_args(argc, argv, "-pfft_on", 0, PFFT_SWITCH, switch);

that is executed via

::

    ./test -pfft_x 3.1 -pfft_np 2 3 -pfft_n 8 16 32 -pfft_on

will read :code:\`x=3.1\`, :code:\`np[2] = {2,3}\`,
:code:\`n[3]={8,16,32}\`, and turn on the :code:\`switch=1\`. Note the
address operator :code:\`&\` in front of :code:\`x\` in the second line!
Furthermore, note that the initialization of all variables with default
values before the call of :code:\`pfft:sub:`g`\ et\ :sub:`a`\ rgs\`
avoids trouble if the user does not provide all the command line
arguments.

Parallel Substitutes for :code:\`vprintf\`, :code:\`fprintf\`, and :code:\`printf\`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The following functions are similar to the standard C function
:code:\`vfprintf\`, :code:\`fprintf\` and :code:\`printf\` with the
exception, that only rank :code:\`0\` within the given communicator
:code:\`comm\` will produce output. The intension is to avoid the flood
of messages that is produced when simple :code:\`printf\` statement are
run in parallel.

::

    void pfft_vfprintf(
        MPI_Comm comm, FILE *stream, const char *format, va_list ap);
    void pfft_fprintf(
        MPI_Comm comm, FILE *stream, const char *format, ...);
    void pfft_printf(
        MPI_Comm comm, const char *format, ...);

Generating Periodic Cartesian Communicators
-------------------------------------------

Based on the processes that are part of the given communicator
:code:\`comm\` the following routine

::

    int pfft_create_procmesh_1d(
        MPI_Comm comm, int np0,
        MPI_Comm *comm_cart_1d);

allocates and creates a one-dimensional, periodic, Cartesian
communicator :code:\`comm:sub:`c`\ art\ :sub:`1`\ d\` of size
:code:\`np0\`. Thereby, a non-zero error code is returned whenever
:code:\`np0\` does not fit the size of :code:\`comm\`. The memory of the
generated communicator should be released with
:code:\`MPI:sub:`C`\ omm\ :sub:`f`\ ree\` after usage. Analogously, use

::

    int pfft_create_procmesh_2d(
        MPI_Comm comm, int np0, int np1,
        MPI_Comm *comm_cart_2d);

in order to allocate and create two-dimensional, periodic, Cartesian
communicator :code:\`comm:sub:`c`\ art\ :sub:`2`\ d\` of size
:code:\`np0\*np1\` or

::

    int pfft_create_procmesh(
        int rnk_np, MPI_Comm comm, const int *np,
        MPI_Comm *comm_cart);

in order to allocate and create a :code:\`rnk:sub:`n`\ p\`-dimensional,
periodic, Cartesian communicator of size
:code:\`np[0]\*np[1]\*...\*np[rnk:sub:`n`\ p-1]\`. Hereby, :code:\`np\`
is an array of length :code:\`rnk:sub:`n`\ p\`. Again, the memory of the
generated communicator should be released with
:code:\`MPI:sub:`C`\ omm\ :sub:`f`\ ree\` after usage.
